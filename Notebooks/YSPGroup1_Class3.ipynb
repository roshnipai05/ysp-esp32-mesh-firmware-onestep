{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Moderation Engine"
      ],
      "metadata": {
        "id": "B4u2x5OBsms9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have been recruited by a software developer who is building their own social media platform. You have been tasked with the development and implementation of the platform's **moderation engine**.\n",
        "\n",
        "(A moderation engine detects any banned strings and penalizes the users based on severity and frequency of offense. The purpose of the moderation engine is to ensure that topics that are harmful, illegal, or even simply insensitive are not discussed on the platform.)\n",
        "\n",
        "#Flagging System#\n",
        "\n",
        "Your first step is to develop a **function** that flags a post when it detects a banned substring. Create a list of banned strings using which you can test your function. Your function should maintain a count of the number of times the user has been flagged and let the user know. If a post is not flagged, the post must be stored for future reference."
      ],
      "metadata": {
        "id": "zHxkiKX1GjiP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bYVpLnqRFJtX"
      },
      "outputs": [],
      "source": [
        "store =[]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting System\n",
        "\n",
        "Very often, users attempt to bypass or mislead the moderation engines by using codewords, intentionally misspelling words, or conversing in a language outside of its native script. This behaviour often causes offensive posts to not be flagged, or normal posts to be wrongfully flagged.\n",
        "\n",
        "Your next step is to develop a **voting system** for the platform. Voting systems allow users to evaluate each other's posts and influence their visibility. In an unbiased space, an majority of negative notes can indicate that a post is offensive.\n",
        "\n",
        "Create a function that goes iterates through the posts saved previously and asks the user to either +vote or -vote them. After iterating through all posts, the function must inform you which posts have received a negative sum of votes and flag the user.\n",
        "\n",
        "‚ÄºÔ∏è Hint: Since each post will be voted individually, its corresponding sum of votes must be stored with it.\n",
        "\n",
        "üîß Bonus: Voting systems require a lot of people to vote in order to maintain a balance in authority over the outcome. Think of a way through which multiple votes can be registered before the function returns you the sum for each post.\n"
      ],
      "metadata": {
        "id": "F6VnbBisvWlt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckvMrXBxyLvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content Hiding System\n",
        "\n",
        "Now that you have developed the flagging and voting systems, you must decide a threshold of flags after which the user's posts are completely hidden. Social media platforms, in cases of multiple flags, hide the offender's posts as a precaution. Users are sometimes given the option to set their own preferences\n",
        "\n",
        "Your last step is to step the **content hiding system** up. The function will ask the user to specify the number of flags after which an offender should be hidden from their view.\n",
        "\n",
        "üîß Challenge:"
      ],
      "metadata": {
        "id": "tusrN-zHyMFM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UiXSCs9OEso0"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}